#!/usr/bin/env python3
"""
BirdRiskSim Aviation Detection Manager
ìƒˆë–¼-í•­ê³µê¸° ê°ì§€ë¥¼ ìœ„í•œ í†µí•© YOLO ê´€ë¦¬ ëª¨ë“ˆ

4ê°œ íŒŒì¼ì—ì„œ ë°˜ë³µë˜ë˜ YOLO ê´€ë ¨ ë¡œì§ì„ í†µí•©:
- real_time_pipeline.py
- apply_yolo_to_sync_capture.py  
- apply_yolo_to_sync_video.py
- triangulate.py
"""

import cv2
import numpy as np
import time
from pathlib import Path
from typing import List, Dict, Optional, Tuple, Union
from ultralytics import YOLO
import torch
import warnings

warnings.filterwarnings('ignore')

class AviationDetector:
    """í•­ê³µ ê°ì²´ ê°ì§€ í†µí•© ê´€ë¦¬ì"""
    
    def __init__(self, model_path: Optional[str] = None, confidence_threshold: float = 0.25):
        """
        í•­ê³µ ê°ì§€ê¸° ì´ˆê¸°í™”
        
        Args:
            model_path: YOLO ëª¨ë¸ ê²½ë¡œ (Noneì´ë©´ ìë™ íƒì§€)
            confidence_threshold: ê°ì§€ ì‹ ë¢°ë„ ì„ê³„ê°’
        """
        self.model_path = model_path
        self.confidence_threshold = confidence_threshold
        self.model = None
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        if self.device == 'cpu':
            print("âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        else:
            print(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name()}")
            print(f"  GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
        
        # í´ë˜ìŠ¤ ì •ë³´ (BirdRiskSim í‘œì¤€)
        self.class_names = {0: 'Flock', 1: 'Airplane'}
        self.class_colors = {
            0: (0, 255, 0),    # ì´ˆë¡ìƒ‰ - Flock
            1: (0, 0, 255),    # ë¹¨ê°„ìƒ‰ - Airplane
        }
        
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
        self.project_root = Path(__file__).parent.parent
        
        # ëª¨ë¸ ë¡œë“œ
        self._load_model()
        
    def _find_latest_model(self) -> Optional[Path]:
        """ìµœì‹  YOLO ëª¨ë¸ ìë™ íƒì§€ (4ê°œ íŒŒì¼ì—ì„œ ì¤‘ë³µë˜ë˜ ë¡œì§)"""
        try:
            train_runs_dir = self.project_root / "training/yolo/runs/train"
            
            if not train_runs_dir.exists():
                print(f"âŒ í•™ìŠµ ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {train_runs_dir}")
                return None
            
            # bird_detection_ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” í´ë”ë“¤ ì°¾ê¸°
            bird_detection_dirs = list(train_runs_dir.glob("bird_detection_*"))
            if not bird_detection_dirs:
                print("âŒ bird_detection í•™ìŠµ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ê°€ì¥ ìµœì‹  í´ë” ì„ íƒ (ìˆ˜ì • ì‹œê°„ ê¸°ì¤€)
            latest_dir = max(bird_detection_dirs, key=lambda d: d.stat().st_mtime)
            model_path = latest_dir / "weights/best.pt"
            
            if not model_path.exists():
                print(f"âŒ ìµœì‹  ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                return None
            
            print(f"ğŸ” ìµœì‹  YOLO ëª¨ë¸ ë°œê²¬: {latest_dir.name}")
            return model_path
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ íƒì§€ ì˜¤ë¥˜: {e}")
            return None
    
    def _load_model(self) -> bool:
        """YOLO ëª¨ë¸ ë¡œë“œ"""
        try:
            # ëª¨ë¸ ê²½ë¡œ ê²°ì •
            if self.model_path is None:
                model_path = self._find_latest_model()
                if model_path is None:
                    return False
            else:
                model_path = Path(self.model_path)
                if not model_path.exists():
                    print(f"âŒ ì§€ì •ëœ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                    return False
            
            # ëª¨ë¸ ë¡œë“œ (device ëª…ì‹œì  ì§€ì •)
            self.model = YOLO(model_path)
            self.model.to(self.device)  # GPU/CPU ì„¤ì •
            self.model_path = model_path
            print(f"âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path.name} ({self.device} ì‚¬ìš©)")
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def detect_single_image(self, image: Union[str, Path, np.ndarray], 
                           camera_id: Optional[str] = None,
                           return_raw: bool = False) -> List[Dict]:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ê°ì²´ ê°ì§€ (3ê°œ íŒŒì¼ì—ì„œ ì¤‘ë³µë˜ë˜ ë¡œì§ í†µí•©)
        
        Args:
            image: ì´ë¯¸ì§€ ê²½ë¡œ ë˜ëŠ” numpy ë°°ì—´
            camera_id: ì¹´ë©”ë¼ ì‹ë³„ì (ì„ íƒì‚¬í•­)
            return_raw: ì›ì‹œ YOLO ê²°ê³¼ ë°˜í™˜ ì—¬ë¶€
            
        Returns:
            ê°ì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if self.model is None:
            print("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            if isinstance(image, (str, Path)):
                img = cv2.imread(str(image))
                if img is None:
                    print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image}")
                    return []
            else:
                img = image
            
            # ğŸš€ GPU ë©”ëª¨ë¦¬ ìµœì í™”: ìºì‹œ ì •ë¦¬
            if self.device == 'cuda':
                torch.cuda.empty_cache()
            
            # YOLO ì¶”ë¡  (ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ìœ ì§€)
            start_time = time.time()
            results = self.model(img, conf=self.confidence_threshold, verbose=False)
            inference_time = time.time() - start_time
            
            result = results[0]
            detections = []
            
            if result.boxes is not None:
                boxes = result.boxes.xyxy.cpu().numpy()
                confidences = result.boxes.conf.cpu().numpy()
                classes = result.boxes.cls.cpu().numpy().astype(int)
                
                for box, conf, cls in zip(boxes, confidences, classes):
                    x1, y1, x2, y2 = box
                    
                    center_x = (x1 + x2) / 2
                    center_y = (y1 + y2) / 2
                    width = x2 - x1
                    height = y2 - y1
                    
                    detection = {
                        'class_id': int(cls),
                        'class_name': self.class_names.get(cls, 'Unknown'),
                        'confidence': float(conf),
                        'bbox': [float(x1), float(y1), float(x2), float(y2)],
                        'center': [float(center_x), float(center_y)],
                        'width': float(width),
                        'height': float(height),
                        'inference_time': inference_time
                    }
                    
                    # ì¹´ë©”ë¼ ID ì¶”ê°€ (ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ìš©)
                    if camera_id:
                        detection['camera'] = camera_id
                    
                    # ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
                    detection['class'] = detection['class_name']
                    
                    detections.append(detection)
            
            # ğŸš€ GPU ë©”ëª¨ë¦¬ ìµœì í™”: ê²°ê³¼ ì²˜ë¦¬ í›„ ìºì‹œ ì •ë¦¬
            if self.device == 'cuda':
                torch.cuda.empty_cache()
            
            # ì›ì‹œ ê²°ê³¼ ë°˜í™˜ ì˜µì…˜
            if return_raw:
                return {'detections': detections, 'raw_results': results}
            
            return detections
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ê°ì§€ ì˜¤ë¥˜: {e}")
            return []
    
    def detect_batch_images(self, image_paths: List[Union[str, Path]], 
                           progress_callback: Optional[callable] = None) -> Dict[str, List[Dict]]:
        """
        ë°°ì¹˜ ì´ë¯¸ì§€ ê°ì§€ (apply_yolo_to_sync_capture.py ë¡œì§ ê¸°ë°˜)
        
        Args:
            image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°± í•¨ìˆ˜
            
        Returns:
            íŒŒì¼ëª…ë³„ ê°ì§€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        results = {}
        total_images = len(image_paths)
        
        print(f"ğŸ“Š ë°°ì¹˜ ê°ì§€ ì‹œì‘: {total_images}ê°œ ì´ë¯¸ì§€")
        
        for i, image_path in enumerate(image_paths):
            image_path = Path(image_path)
            
            # ê°ì§€ ìˆ˜í–‰
            detections = self.detect_single_image(image_path)
            results[image_path.name] = detections
            
            # ì§„í–‰ ìƒí™© ì½œë°±
            if progress_callback:
                progress_callback(i + 1, total_images, image_path.name)
            elif (i + 1) % 10 == 0:
                print(f"  ì§„í–‰: {i + 1}/{total_images} ({(i + 1)/total_images*100:.1f}%)")
        
        print(f"âœ… ë°°ì¹˜ ê°ì§€ ì™„ë£Œ: {len(results)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬")
        return results
    
    def detect_video_frame(self, frame: np.ndarray, frame_number: int = 0, 
                          timestamp: float = 0.0) -> List[Dict]:
        """
        ë¹„ë””ì˜¤ í”„ë ˆì„ ê°ì§€ (apply_yolo_to_sync_video.py ë¡œì§ ê¸°ë°˜)
        
        Args:
            frame: ë¹„ë””ì˜¤ í”„ë ˆì„ (numpy ë°°ì—´)
            frame_number: í”„ë ˆì„ ë²ˆí˜¸
            timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
            
        Returns:
            ê°ì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (í”„ë ˆì„ ì •ë³´ í¬í•¨)
        """
        detections = self.detect_single_image(frame)
        
        # í”„ë ˆì„ ì •ë³´ ì¶”ê°€
        for detection in detections:
            detection['frame_number'] = frame_number
            detection['timestamp'] = timestamp
        
        return detections
    
    def get_model_info(self) -> Dict:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        if self.model is None:
            return {'loaded': False}
        
        return {
            'loaded': True,
            'model_path': str(self.model_path),
            'confidence_threshold': self.confidence_threshold,
            'class_names': self.class_names,
            'model_type': 'YOLOv8'
        }
    
    def set_confidence_threshold(self, threshold: float):
        """ì‹ ë¢°ë„ ì„ê³„ê°’ ë³€ê²½"""
        if 0.0 <= threshold <= 1.0:
            self.confidence_threshold = threshold
            print(f"âœ… ì‹ ë¢°ë„ ì„ê³„ê°’ ë³€ê²½: {threshold}")
        else:
            print(f"âŒ ì˜ëª»ëœ ì„ê³„ê°’: {threshold} (0.0-1.0 ë²”ìœ„)")
    
    def reload_model(self, model_path: Optional[str] = None):
        """ëª¨ë¸ ì¬ë¡œë“œ"""
        self.model_path = model_path
        self.model = None
        return self._load_model()
    
    @staticmethod
    def format_detection_for_realtime(detections: List[Dict], camera_letter: str) -> List[Dict]:
        """ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        formatted = []
        for det in detections:
            formatted.append({
                'camera': camera_letter,
                'class': det['class_name'],
                'bbox': det['bbox'],
                'center': det['center'],
                'confidence': det['confidence']
            })
        return formatted
    
    @staticmethod
    def format_detection_for_batch(detections: List[Dict], frame_number: int, 
                                  timestamp: float = 0.0) -> List[Dict]:
        """ë°°ì¹˜ ì²˜ë¦¬ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        formatted = []
        for det in detections:
            formatted.append({
                'frame_number': frame_number,
                'timestamp': timestamp,
                'class_id': det['class_id'],
                'class_name': det['class_name'],
                'confidence': det['confidence'],
                'bbox': det['bbox'],
                'center': det['center'],
                'width': det['width'],
                'height': det['height']
            })
        return formatted

    def detect_batch_images_realtime(self, images: Dict[str, Union[str, Path, np.ndarray]]) -> List[Dict]:
        """
        ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ìš© ë°°ì¹˜ ì´ë¯¸ì§€ ê°ì§€ (ì„±ëŠ¥ ìµœì í™”)
        
        Args:
            images: {camera_id: image_path_or_array} ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ëª¨ë“  ì¹´ë©”ë¼ì˜ ê°ì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if self.model is None:
            print("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            # ğŸš€ GPU ë©”ëª¨ë¦¬ ìµœì í™”: ë°°ì¹˜ ì²˜ë¦¬ ì „ ìºì‹œ ì •ë¦¬
            if self.device == 'cuda':
                torch.cuda.empty_cache()
            
            # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
            batch_images = []
            camera_ids = []
            
            for camera_id, image in images.items():
                if isinstance(image, (str, Path)):
                    img = cv2.imread(str(image))
                    if img is None:
                        print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image}")
                        continue
                else:
                    img = image
                
                batch_images.append(img)
                camera_ids.append(camera_id)
            
            if not batch_images:
                return []
            
            # ğŸš€ ë°°ì¹˜ ì¶”ë¡  (ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬)
            start_time = time.time()
            results = self.model(batch_images, conf=self.confidence_threshold, verbose=False)
            inference_time = time.time() - start_time
            
            # ê²°ê³¼ ì²˜ë¦¬
            all_detections = []
            
            for i, (result, camera_id) in enumerate(zip(results, camera_ids)):
                if result.boxes is not None:
                    boxes = result.boxes.xyxy.cpu().numpy()
                    confidences = result.boxes.conf.cpu().numpy()
                    classes = result.boxes.cls.cpu().numpy().astype(int)
                    
                    for box, conf, cls in zip(boxes, confidences, classes):
                        x1, y1, x2, y2 = box
                        center_x = (x1 + x2) / 2
                        center_y = (y1 + y2) / 2
                        width = x2 - x1
                        height = y2 - y1
                        
                        detection = {
                            'class_id': int(cls),
                            'class_name': self.class_names.get(cls, 'Unknown'),
                            'confidence': float(conf),
                            'bbox': [float(x1), float(y1), float(x2), float(y2)],
                            'center': [float(center_x), float(center_y)],
                            'width': float(width),
                            'height': float(height),
                            'inference_time': inference_time / len(batch_images),  # ë°°ì¹˜ë‹¹ í‰ê·  ì‹œê°„
                            'camera': camera_id,
                            'class': self.class_names.get(cls, 'Unknown')  # ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ í˜¸í™˜ì„±
                        }
                        
                        all_detections.append(detection)
            
            # ğŸš€ GPU ë©”ëª¨ë¦¬ ìµœì í™”: ë°°ì¹˜ ì²˜ë¦¬ í›„ ìºì‹œ ì •ë¦¬
            if self.device == 'cuda':
                torch.cuda.empty_cache()
            
            print(f"ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(batch_images)}ê°œ ì´ë¯¸ì§€, {len(all_detections)}ê°œ ê°ì²´ ê°ì§€ ({inference_time*1000:.1f}ms)")
            
            return all_detections
            
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì´ë¯¸ì§€ ê°ì§€ ì˜¤ë¥˜: {e}")
            return []

# í¸ì˜ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±)
def load_latest_yolo_model(confidence_threshold: float = 0.25) -> Optional[AviationDetector]:
    """ìµœì‹  YOLO ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë¡œë“œí•˜ëŠ” í¸ì˜ í•¨ìˆ˜"""
    detector = AviationDetector(confidence_threshold=confidence_threshold)
    if detector.model is None:
        return None
    return detector

def detect_objects_in_image(image_path: Union[str, Path], 
                          confidence_threshold: float = 0.25) -> List[Dict]:
    """ë‹¨ì¼ ì´ë¯¸ì§€ ê°ì§€ í¸ì˜ í•¨ìˆ˜"""
    detector = load_latest_yolo_model(confidence_threshold)
    if detector is None:
        return []
    return detector.detect_single_image(image_path)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    print("ğŸš€ AviationDetector í…ŒìŠ¤íŠ¸")
    
    # ê°ì§€ê¸° ì´ˆê¸°í™”
    detector = AviationDetector()
    
    if detector.model is not None:
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        print(f"ğŸ“Š ëª¨ë¸ ì •ë³´: {detector.get_model_info()}")
    else:
        print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨") 