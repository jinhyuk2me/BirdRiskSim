using UnityEngine;
using UnityEngine.InputSystem;
using System.Collections;
using System.Collections.Generic;
using System.IO;
using System;

// ===================================================================
// ğŸ“¸ Camera Parameter Serialization Structures
// These structs are needed because Unity's JsonUtility cannot serialize
// native Vector or Matrix types directly.
// ===================================================================
[System.Serializable]
public struct SerializableVector2
{
    public float x, y;
    public SerializableVector2(Vector2 v) { x = v.x; y = v.y; }
}

[System.Serializable]
public struct SerializableVector3
{
    public float x, y, z;
    public SerializableVector3(Vector3 v) { x = v.x; y = v.y; z = v.z; }
}

[System.Serializable]
public struct SerializableQuaternion
{
    public float x, y, z, w;
    public SerializableQuaternion(Quaternion q) { x = q.x; y = q.y; z = q.z; w = q.w; }
}

[System.Serializable]
public struct SerializableMatrix4x4
{
    public float m00, m01, m02, m03;
    public float m10, m11, m12, m13;
    public float m20, m21, m22, m23;
    public float m30, m31, m32, m33;

    public SerializableMatrix4x4(Matrix4x4 m)
    {
        m00 = m.m00; m01 = m.m01; m02 = m.m02; m03 = m.m03;
        m10 = m.m10; m11 = m.m11; m12 = m.m12; m13 = m.m13;
        m20 = m.m20; m21 = m.m21; m22 = m.m22; m23 = m.m23;
        m30 = m.m30; m31 = m.m31; m32 = m.m32; m33 = m.m33;
    }
}

[System.Serializable]
public class CameraParameters
{
    public string cameraName;
    public int imageWidth;
    public int imageHeight;
    
    // --- Intrinsic Parameters ---
    public float fieldOfView_vertical; // Unity's FoV is vertical
    public SerializableVector2 sensorSize; // In millimeters
    
    // --- Extrinsic Parameters (Unity's Left-Handed World Space) ---
    public SerializableVector3 position_UnityWorld;
    public SerializableQuaternion rotation_UnityWorld;
    
    // --- Full Matrices (for advanced use) ---
    public string matrixCoordinateSystemNote = "All matrices below are in Unity's Left-Handed Coordinate System.";
    public SerializableMatrix4x4 worldToCameraMatrix; // View Matrix (V)
    public SerializableMatrix4x4 projectionMatrix;    // Projection Matrix (P)
    
    public string pythonConversionNote = "For Python/OpenCV, coordinate system conversion is required. Unity: LHS, Y-up. OpenCV: RHS, Y-down.";
}

public class SyncCaptureManager : MonoBehaviour
{
    [Header("ğŸ¬ Synchronized Video Recording System")]
    [Space(10)]
    
    [Header("Camera Configuration")]
    [Tooltip("ë‘ ëŒ€ ì´ìƒì˜ ì¹´ë©”ë¼ (ì‚¼ê°ì¸¡ëŸ‰ìš©)")]
    public Camera[] recordingCameras;
    
    [Header("Recording Settings")]
    [Range(15, 60)]
    public int frameRate = 30;
    
    [Range(10, 300)]
    public int recordingDuration = 60; // ì´ˆ
    
    [Header("Image Quality")]
    public int imageWidth = 1280;
    public int imageHeight = 720;
    
    [Range(50, 100)]
    public int jpegQuality = 90;
    
    [Header("Output Settings")]
    public bool saveAsSequence = true; // í”„ë ˆì„ ì‹œí€€ìŠ¤ë¡œ ì €ì¥
    public bool generateVideoFiles = false; // FFmpeg í•„ìš”
    public bool saveTimestampFile = true; // ì‹œê°„ ë™ê¸°í™” ì •ë³´
    
    [Header("Performance")]
    public bool enableMemoryOptimization = true;
    public bool showProgressInConsole = true;
    
    [Header("ğŸ® Recording Controls")]
    [Space(5)]
    public KeyCode startRecordingKey = KeyCode.R;
    public KeyCode stopRecordingKey = KeyCode.T;
    
    [Header("ë¹„í–‰ê¸° ì—°ë™ ìë™ ë…¹í™”")]
    [Tooltip("ë¹„í–‰ê¸° ìƒì„±/ì†Œë©¸ì— ë”°ë¼ ìë™ìœ¼ë¡œ ë…¹í™” ì‹œì‘/ì¢…ë£Œ")]
    public bool airplaneAutoRecording = false;
    [Tooltip("ë¹„í–‰ê¸° ì†Œë©¸ í›„ ë…¹í™” ì¢…ë£Œê¹Œì§€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)")]
    public float recordingStopDelay = 2f;
    
    [Header("ê²½ë¡œ êµ¬ë¶„")]
    [Tooltip("ë…¹í™”í•  ê²½ë¡œ ì´ë¦„ (í´ë”ëª…ì— í¬í•¨ë¨)")]
    public string routeName = "Path_A";
    [Tooltip("ê²½ë¡œë³„ í´ë” êµ¬ë¶„ í™œì„±í™”")]
    public bool enableRouteBasedFolders = true;
    [Tooltip("ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ë¡œ ëª©ë¡")]
    public string[] availableRoutes = {"Path_A", "Path_B", "Path_C", "Path_D"};
    
    // Private variables
    private RenderTexture[] renderTextures;
    private Texture2D[] texture2Ds;
    private bool isRecording = false;
    private int currentFrame = 0;
    private string outputFolder;
    private List<double> frameTimestamps;
    private Coroutine recordingCoroutine;
    
    // UI Display
    private GUIStyle labelStyle;
    private bool showGUI = true;

    // ë¹„í–‰ê¸° ìë™ ë…¹í™” ê´€ë ¨
    private List<GameObject> trackedAirplanes = new List<GameObject>();
    private Coroutine stopRecordingCoroutine;

    void Start()
    {
        InitializeCapture();
        SetupGUIStyle();
        
        // ë¹„í–‰ê¸° ìë™ ë…¹í™” ëª¨ë“œ ì´ˆê¸°í™”
        if (airplaneAutoRecording)
        {
            StartCoroutine(MonitorAirplanes());
        }
    }

    void SetupGUIStyle()
    {
        labelStyle = new GUIStyle();
        labelStyle.fontSize = 16;
        labelStyle.normal.textColor = Color.white;
        labelStyle.fontStyle = FontStyle.Bold;
    }

    void InitializeCapture()
    {
        if (recordingCameras == null || recordingCameras.Length < 2)
        {
            Debug.LogError("âŒ [SyncCapture] ì‚¼ê°ì¸¡ëŸ‰ì„ ìœ„í•´ ìµœì†Œ 2ëŒ€ì˜ ì¹´ë©”ë¼ê°€ í•„ìš”í•©ë‹ˆë‹¤!");
            enabled = false;
            return;
        }

        // RenderTexture ë° Texture2D ë°°ì—´ ì´ˆê¸°í™”
        renderTextures = new RenderTexture[recordingCameras.Length];
        texture2Ds = new Texture2D[recordingCameras.Length];
        frameTimestamps = new List<double>();

        for (int i = 0; i < recordingCameras.Length; i++)
        {
            if (recordingCameras[i] == null)
            {
                Debug.LogError($"âŒ [SyncCapture] Camera {i}ê°€ nullì…ë‹ˆë‹¤!");
                enabled = false;
                return;
            }

            renderTextures[i] = new RenderTexture(imageWidth, imageHeight, 24, RenderTextureFormat.ARGB32);
            texture2Ds[i] = new Texture2D(imageWidth, imageHeight, TextureFormat.RGB24, false);
        }

        Debug.Log($"âœ… [SyncCapture] {recordingCameras.Length}ëŒ€ ì¹´ë©”ë¼ ë™ê¸°í™” ìº¡ì²˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ");
        Debug.Log($"ğŸ“Š [SyncCapture] í•´ìƒë„: {imageWidth}x{imageHeight}, FPS: {frameRate}, ë…¹í™”ì‹œê°„: {recordingDuration}ì´ˆ");
    }

    // ğŸ›©ï¸ ë¹„í–‰ê¸° ëª¨ë‹ˆí„°ë§ ì½”ë£¨í‹´
    IEnumerator MonitorAirplanes()
    {
        Debug.Log("âœˆï¸ [SyncCapture] ë¹„í–‰ê¸° ìë™ ë…¹í™” ëª¨ë‹ˆí„°ë§ ì‹œì‘");
        
        while (airplaneAutoRecording)
        {
            // í˜„ì¬ ì”¬ì˜ ëª¨ë“  ë¹„í–‰ê¸° ì°¾ê¸°
            GameObject[] currentAirplanes = GameObject.FindGameObjectsWithTag("Airplane");
            
            // ìƒˆë¡œìš´ ë¹„í–‰ê¸° ê°ì§€
            foreach (GameObject airplane in currentAirplanes)
            {
                if (!trackedAirplanes.Contains(airplane))
                {
                    OnAirplaneSpawned(airplane);
                }
            }
            
            // ì†Œë©¸ëœ ë¹„í–‰ê¸° ê°ì§€
            for (int i = trackedAirplanes.Count - 1; i >= 0; i--)
            {
                if (trackedAirplanes[i] == null)
                {
                    OnAirplaneDestroyed();
                    trackedAirplanes.RemoveAt(i);
                }
            }
            
            yield return new WaitForSeconds(0.5f); // 0.5ì´ˆë§ˆë‹¤ ì²´í¬
        }
    }
    
    // ğŸ›©ï¸ ë¹„í–‰ê¸° ìƒì„± ê°ì§€
    void OnAirplaneSpawned(GameObject airplane)
    {
        trackedAirplanes.Add(airplane);
        Debug.Log($"âœˆï¸ [SyncCapture] ë¹„í–‰ê¸° ìƒì„± ê°ì§€: {airplane.name}");
        
        // ğŸ¯ ìƒˆ ë¹„í–‰ê¸°ê°€ ìƒì„±ë˜ë©´ í•­ìƒ ìƒˆë¡œìš´ ë…¹í™” ì‹œì‘
        if (isRecording)
        {
            Debug.Log("ğŸ”„ [SyncCapture] ìƒˆ ë¹„í–‰ê¸° ìƒì„±ìœ¼ë¡œ ì´ì „ ë…¹í™” ì¢…ë£Œ í›„ ìƒˆ ë…¹í™” ì‹œì‘");
            StopRecording();
            // ì ì‹œ ëŒ€ê¸° í›„ ìƒˆ ë…¹í™” ì‹œì‘ (íŒŒì¼ ì €ì¥ ì™„ë£Œ ëŒ€ê¸°)
            StartCoroutine(StartNewRecordingAfterDelay());
        }
        else
        {
            Debug.Log("ğŸ¬ [SyncCapture] ë¹„í–‰ê¸° ìƒì„±ìœ¼ë¡œ ìë™ ë…¹í™” ì‹œì‘");
            StartSynchronizedRecording();
        }
        
        // ë…¹í™” ì¢…ë£Œ ì½”ë£¨í‹´ì´ ì‹¤í–‰ ì¤‘ì´ë©´ ì·¨ì†Œ
        if (stopRecordingCoroutine != null)
        {
            StopCoroutine(stopRecordingCoroutine);
            stopRecordingCoroutine = null;
            Debug.Log("â¸ï¸ [SyncCapture] ë…¹í™” ì¢…ë£Œ ì˜ˆì•½ ì·¨ì†Œ");
        }
    }
    
    // ğŸ¬ ì§€ì—°ëœ ìƒˆ ë…¹í™” ì‹œì‘
    IEnumerator StartNewRecordingAfterDelay()
    {
        yield return new WaitForSeconds(0.5f); // íŒŒì¼ ì €ì¥ ì™„ë£Œ ëŒ€ê¸°
        if (!isRecording) // ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸
        {
            Debug.Log("ğŸ¬ [SyncCapture] ìƒˆ ë…¹í™” ì‹œì‘");
            StartSynchronizedRecording();
        }
    }
    
    // ğŸ›©ï¸ ë¹„í–‰ê¸° ì†Œë©¸ ê°ì§€
    void OnAirplaneDestroyed()
    {
        Debug.Log($"âœˆï¸ [SyncCapture] ë¹„í–‰ê¸° ì†Œë©¸ ê°ì§€ (ë‚¨ì€ ë¹„í–‰ê¸°: {trackedAirplanes.Count - 1}ê°œ)");
        
        // ëª¨ë“  ë¹„í–‰ê¸°ê°€ ì†Œë©¸ë˜ë©´ ë…¹í™” ì¢…ë£Œ ì˜ˆì•½
        if (trackedAirplanes.Count <= 1 && isRecording) // <= 1 because we haven't removed it yet
        {
            if (stopRecordingCoroutine != null)
            {
                StopCoroutine(stopRecordingCoroutine);
            }
            stopRecordingCoroutine = StartCoroutine(DelayedStopRecording());
        }
    }
    
    // ğŸ›©ï¸ ì§€ì—°ëœ ë…¹í™” ì¢…ë£Œ
    IEnumerator DelayedStopRecording()
    {
        Debug.Log($"â° [SyncCapture] {recordingStopDelay}ì´ˆ í›„ ë…¹í™” ì¢…ë£Œ ì˜ˆì •");
        yield return new WaitForSeconds(recordingStopDelay);
        
        // ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸ (ìƒˆ ë¹„í–‰ê¸°ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ëŠ”ì§€)
        if (trackedAirplanes.Count == 0 && isRecording)
        {
            Debug.Log("ğŸ›‘ [SyncCapture] ëª¨ë“  ë¹„í–‰ê¸° ì†Œë©¸ë¡œ ìë™ ë…¹í™” ì¢…ë£Œ");
            StopRecording();
        }
        
        stopRecordingCoroutine = null;
    }
    
    // ğŸ›©ï¸ ì™¸ë¶€ì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ ë©”ì„œë“œë“¤
    public void EnableAirplaneAutoRecording()
    {
        if (!airplaneAutoRecording)
        {
            airplaneAutoRecording = true;
            StartCoroutine(MonitorAirplanes());
            Debug.Log("âœ… [SyncCapture] ë¹„í–‰ê¸° ìë™ ë…¹í™” ëª¨ë“œ í™œì„±í™”");
        }
    }
    
    public void DisableAirplaneAutoRecording()
    {
        airplaneAutoRecording = false;
        trackedAirplanes.Clear();
        if (stopRecordingCoroutine != null)
        {
            StopCoroutine(stopRecordingCoroutine);
            stopRecordingCoroutine = null;
        }
        Debug.Log("âŒ [SyncCapture] ë¹„í–‰ê¸° ìë™ ë…¹í™” ëª¨ë“œ ë¹„í™œì„±í™”");
    }

    void Update()
    {
        // ìƒˆë¡œìš´ Input System ì‚¬ìš©
        if (Keyboard.current != null)
        {
            // R í‚¤ë¡œ ë…¹í™” ì‹œì‘
            if (Keyboard.current.rKey.wasPressedThisFrame && !isRecording)
            {
                StartSynchronizedRecording();
            }
            // T í‚¤ë¡œ ë…¹í™” ì¤‘ì§€
            else if (Keyboard.current.tKey.wasPressedThisFrame && isRecording)
            {
                StopRecording();
            }
        }
    }

    void OnGUI()
    {
        if (!showGUI) return;

        // ğŸ¯ ìƒë‹¨ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ìœ„ì¹˜ ì´ë™
        float panelWidth = 350f;
        float panelHeight = 120f;
        float rightMargin = 10f;
        float topMargin = 10f;
        
        float panelX = Screen.width - panelWidth - rightMargin;
        float panelY = topMargin;

        // ë…¹í™” ìƒíƒœ í‘œì‹œ
        GUI.Box(new Rect(panelX, panelY, panelWidth, panelHeight), "");
        
        GUI.Label(new Rect(panelX + 10, panelY + 10, panelWidth - 20, 25), "ğŸ¬ Synchronized Video Capture", labelStyle);
        
        string status = isRecording ? $"ğŸ”´ Recording: {currentFrame}/{frameRate * recordingDuration}" 
                                    : "âšª Ready to Record";
        
        // ë¹„í–‰ê¸° ìë™ ë…¹í™” ëª¨ë“œ í‘œì‹œ
        if (airplaneAutoRecording)
        {
            status += $" | âœˆï¸ Auto ({trackedAirplanes.Count})";
        }
        
        GUI.Label(new Rect(panelX + 10, panelY + 35, panelWidth - 20, 20), status);
        
        GUI.Label(new Rect(panelX + 10, panelY + 55, panelWidth - 20, 20), $"Cameras: {recordingCameras.Length} | Resolution: {imageWidth}x{imageHeight}");
        
        string controls = $"[{startRecordingKey}] Start | [{stopRecordingKey}] Stop";
        GUI.Label(new Rect(panelX + 10, panelY + 75, panelWidth - 20, 20), controls);
        
        if (isRecording)
        {
            float progress = (float)currentFrame / (frameRate * recordingDuration);
            GUI.HorizontalScrollbar(new Rect(panelX + 10, panelY + 95, panelWidth - 20, 20), 0, progress, 0, 1);
        }
    }

    private string GetCaptureBasePath()
    {
        // í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°
        string projectRoot = Path.GetDirectoryName(Application.dataPath);
        return Path.Combine(projectRoot, "data", "sync_capture");
    }

    [ContextMenu("ğŸ¬ Start Synchronized Recording")]
    public void StartSynchronizedRecording()
    {
        if (isRecording)
        {
            Debug.LogWarning("âš ï¸ [SyncCapture] ì´ë¯¸ ë…¹í™” ì¤‘ì…ë‹ˆë‹¤!");
            return;
        }

        // ì¶œë ¥ í´ë” ìƒì„± (ë°€ë¦¬ì´ˆ í¬í•¨ìœ¼ë¡œ ë” ì •ë°€í•œ êµ¬ë¶„)
        string timestamp = DateTime.Now.ToString("yyyyMMdd_HHmmss_fff");
        string folderName;
        
        if (enableRouteBasedFolders && !string.IsNullOrEmpty(routeName))
        {
            folderName = $"Recording_{routeName}_{timestamp}";
        }
        else
        {
            folderName = $"Recording_{timestamp}";
        }
        
        outputFolder = Path.Combine(GetCaptureBasePath(), folderName);
        Directory.CreateDirectory(outputFolder);

        // ê° ì¹´ë©”ë¼ë³„ í´ë” ìƒì„± ë° íŒŒë¼ë¯¸í„° ì €ì¥
        for (int i = 0; i < recordingCameras.Length; i++)
        {
            string cameraName = recordingCameras[i].name;
            string cameraFolder = Path.Combine(outputFolder, cameraName);
            Directory.CreateDirectory(cameraFolder);
            
            // ğŸ¯ ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ì €ì¥ ë¡œì§ í˜¸ì¶œ
            SaveCameraParameters(recordingCameras[i], outputFolder);
        }

        // ë…¹í™” ì‹œì‘
        isRecording = true;
        currentFrame = 0;
        frameTimestamps.Clear();

        recordingCoroutine = StartCoroutine(RecordingLoop());
        
        Debug.Log($"ğŸ¬ [SyncCapture] ë™ê¸°í™” ë…¹í™” ì‹œì‘!");
        Debug.Log($"ğŸ“ [SyncCapture] ì¶œë ¥ í´ë”: {outputFolder}");
    }

    [ContextMenu("ğŸ›‘ Stop Recording")]
    public void StopRecording()
    {
        if (!isRecording) return;

        isRecording = false;
        
        if (recordingCoroutine != null)
        {
            StopCoroutine(recordingCoroutine);
            recordingCoroutine = null;
        }

        // íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì¼ ì €ì¥
        if (saveTimestampFile)
        {
            SaveTimestampFile();
        }

        Debug.Log($"ğŸ›‘ [SyncCapture] ë…¹í™” ì¤‘ì§€! ì´ {currentFrame} í”„ë ˆì„ ì €ì¥");
        Debug.Log($"ğŸ“ [SyncCapture] ì €ì¥ ìœ„ì¹˜: {outputFolder}");

        // ë©”ëª¨ë¦¬ ì •ë¦¬
        if (enableMemoryOptimization)
        {
            System.GC.Collect();
        }
    }

    IEnumerator RecordingLoop()
    {
        float frameInterval = 1f / frameRate;
        int totalFrames = recordingDuration * frameRate;

        while (isRecording && currentFrame < totalFrames)
        {
            double captureTime = Time.realtimeSinceStartupAsDouble;
            
            // ğŸ¯ í•µì‹¬: ëª¨ë“  ì¹´ë©”ë¼ ë™ì‹œ ìº¡ì²˜
            yield return StartCoroutine(CaptureAllCamerasSimultaneously(captureTime));
            
            currentFrame++;
            
            // ì§„í–‰ ìƒí™© ë¡œê·¸
            if (showProgressInConsole && currentFrame % (frameRate * 5) == 0) // 5ì´ˆë§ˆë‹¤
            {
                float progress = (float)currentFrame / totalFrames * 100f;
                float elapsedTime = currentFrame / (float)frameRate;
                Debug.Log($"ğŸ“¹ [SyncCapture] Progress: {progress:F1}% ({elapsedTime:F1}s / {recordingDuration}s)");
            }
            
            // ë©”ëª¨ë¦¬ ìµœì í™”
            if (enableMemoryOptimization && currentFrame % (frameRate * 10) == 0) // 10ì´ˆë§ˆë‹¤
            {
                Resources.UnloadUnusedAssets();
            }
            
            yield return new WaitForSeconds(frameInterval);
        }

        // ìë™ ì¤‘ì§€
        StopRecording();
    }

    IEnumerator CaptureAllCamerasSimultaneously(double timestamp)
    {
        frameTimestamps.Add(timestamp);

        // Step 1: ëª¨ë“  ì¹´ë©”ë¼ì˜ ì›ë³¸ targetTexture ë°±ì—…
        RenderTexture[] originalTargets = new RenderTexture[recordingCameras.Length];
        for (int i = 0; i < recordingCameras.Length; i++)
        {
            originalTargets[i] = recordingCameras[i].targetTexture;
            recordingCameras[i].targetTexture = renderTextures[i];
        }

        // Step 2: ë™ì‹œì— ëª¨ë“  ì¹´ë©”ë¼ ë Œë”ë§
        for (int i = 0; i < recordingCameras.Length; i++)
        {
            recordingCameras[i].Render();
        }

        // Step 3: ë™ì‹œì— ëª¨ë“  í…ìŠ¤ì²˜ ì½ê¸° ë° ì €ì¥
        for (int i = 0; i < recordingCameras.Length; i++)
        {
            RenderTexture.active = renderTextures[i];
            texture2Ds[i].ReadPixels(new Rect(0, 0, imageWidth, imageHeight), 0, 0);
            texture2Ds[i].Apply();

            // íŒŒì¼ ì €ì¥
            byte[] imageData = texture2Ds[i].EncodeToJPG(jpegQuality);
            string cameraName = recordingCameras[i].name;
            
            // ğŸ¯ Defensive Coding: Check if directory exists before writing
            string cameraFolder = Path.Combine(outputFolder, cameraName);
            if (!Directory.Exists(cameraFolder))
            {
                Debug.LogWarning($"[SyncCapture] Directory not found, recreating: {cameraFolder}");
                Directory.CreateDirectory(cameraFolder);
            }

            string filename = Path.Combine(cameraFolder, $"frame_{currentFrame:D6}.jpg");
            
            File.WriteAllBytes(filename, imageData);
        }

        RenderTexture.active = null;

        // Step 4: ì›ë³¸ targetTexture ë³µì›
        for (int i = 0; i < recordingCameras.Length; i++)
        {
            recordingCameras[i].targetTexture = originalTargets[i];
        }

        yield return null; // í•œ í”„ë ˆì„ ëŒ€ê¸°
    }

    private void SaveCameraParameters(Camera cam, string folderPath)
    {
        CameraParameters parameters = new CameraParameters();

        // Populate the parameters
        parameters.cameraName = cam.name;
        parameters.imageWidth = imageWidth;
        parameters.imageHeight = imageHeight;
        
        parameters.fieldOfView_vertical = cam.fieldOfView;
        parameters.sensorSize = new SerializableVector2(cam.sensorSize);
        
        parameters.position_UnityWorld = new SerializableVector3(cam.transform.position);
        parameters.rotation_UnityWorld = new SerializableQuaternion(cam.transform.rotation);
        
        parameters.worldToCameraMatrix = new SerializableMatrix4x4(cam.worldToCameraMatrix);
        parameters.projectionMatrix = new SerializableMatrix4x4(cam.projectionMatrix);

        // Serialize to JSON and save
        string json = JsonUtility.ToJson(parameters, true);
        string filePath = Path.Combine(folderPath, $"{cam.name}_parameters.json");
        
        try
        {
            File.WriteAllText(filePath, json);
            Debug.Log($"ğŸ’¾ [SyncCapture] Camera parameters saved for '{cam.name}' to {filePath}");
        }
        catch (Exception e)
        {
            Debug.LogError($"âŒ [SyncCapture] Failed to save camera parameters for '{cam.name}': {e.Message}");
        }
    }

    void SaveTimestampFile()
    {
        if (frameTimestamps.Count == 0) return;

        // ğŸ¯ Defensive Coding: Check if directory exists before writing
        if (!Directory.Exists(outputFolder))
        {
            Debug.LogWarning($"[SyncCapture] Output folder not found, recreating: {outputFolder}");
            Directory.CreateDirectory(outputFolder);
        }

        string timestampFile = Path.Combine(outputFolder, "frame_timestamps.txt");
        List<string> lines = new List<string>();
        
        lines.Add("# Synchronized Frame Timestamps");
        lines.Add($"# Recording started at: {DateTime.Now:yyyy-MM-dd HH:mm:ss}");
        lines.Add($"# Total frames: {frameTimestamps.Count}");
        lines.Add($"# Frame rate: {frameRate} fps");
        lines.Add($"# Cameras: {string.Join(", ", System.Array.ConvertAll(recordingCameras, c => c.name))}");
        lines.Add("#");
        lines.Add("# Format: frame_number,timestamp_seconds");

        for (int i = 0; i < frameTimestamps.Count; i++)
        {
            lines.Add($"{i:D6},{frameTimestamps[i]:F6}");
        }

        File.WriteAllLines(timestampFile, lines);
        Debug.Log($"ğŸ’¾ [SyncCapture] íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì¼ ì €ì¥: {timestampFile}");
    }

    // ìœ í‹¸ë¦¬í‹° ë©”ì†Œë“œë“¤
    [ContextMenu("ğŸ“Š Show Recording Info")]
    public void ShowRecordingInfo()
    {
        int totalFrames = recordingDuration * frameRate;
        float estimatedSize = (imageWidth * imageHeight * 3 * totalFrames * recordingCameras.Length) / (1024f * 1024f); // MB
        
        Debug.Log("ğŸ“Š [SyncCapture] Recording Information:");
        Debug.Log($"  ğŸ“· Cameras: {recordingCameras.Length}");
        Debug.Log($"  ğŸï¸ Total Frames: {totalFrames}");
        Debug.Log($"  ğŸ“ Resolution: {imageWidth} x {imageHeight}");
        Debug.Log($"  â±ï¸ Duration: {recordingDuration} seconds @ {frameRate} fps");
        Debug.Log($"  ğŸ’¾ Estimated Size: ~{estimatedSize:F1} MB");
    }

    [ContextMenu("ğŸ”§ Validate Setup")]
    public void ValidateSetup()
    {
        bool isValid = true;
        
        if (recordingCameras == null || recordingCameras.Length < 2)
        {
            Debug.LogError("âŒ [SyncCapture] ì‚¼ê°ì¸¡ëŸ‰ì„ ìœ„í•´ ìµœì†Œ 2ëŒ€ì˜ ì¹´ë©”ë¼ê°€ í•„ìš”í•©ë‹ˆë‹¤!");
            isValid = false;
        }

        for (int i = 0; i < recordingCameras.Length; i++)
        {
            if (recordingCameras[i] == null)
            {
                Debug.LogError($"âŒ [SyncCapture] Camera {i}ê°€ nullì…ë‹ˆë‹¤!");
                isValid = false;
            }
        }

        if (frameRate < 15 || frameRate > 60)
        {
            Debug.LogWarning("âš ï¸ [SyncCapture] ê¶Œì¥ í”„ë ˆì„ ë ˆì´íŠ¸: 15-60 fps");
        }

        if (isValid)
        {
            Debug.Log("âœ… [SyncCapture] ì„¤ì • ê²€ì¦ ì™„ë£Œ! ë…¹í™” ì¤€ë¹„ë¨");
        }
    }

    void OnDestroy()
    {
        // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        if (renderTextures != null)
        {
            for (int i = 0; i < renderTextures.Length; i++)
            {
                if (renderTextures[i] != null)
                {
                    renderTextures[i].Release();
                }
            }
        }

        if (isRecording)
        {
            StopRecording();
        }
        
        // ë¹„í–‰ê¸° ìë™ ë…¹í™” ì •ë¦¬
        if (stopRecordingCoroutine != null)
        {
            StopCoroutine(stopRecordingCoroutine);
        }
    }

    // ë””ë²„ê·¸ìš© ê¸°ì¦ˆëª¨
    void OnDrawGizmos()
    {
        if (recordingCameras == null) return;

        // ì¹´ë©”ë¼ ìœ„ì¹˜ì™€ ë°©í–¥ í‘œì‹œ
        Gizmos.color = isRecording ? Color.red : Color.green;
        
        for (int i = 0; i < recordingCameras.Length; i++)
        {
            if (recordingCameras[i] != null)
            {
                Vector3 pos = recordingCameras[i].transform.position;
                Vector3 forward = recordingCameras[i].transform.forward * 2f;
                
                Gizmos.DrawWireSphere(pos, 0.5f);
                Gizmos.DrawRay(pos, forward);
                
                #if UNITY_EDITOR
                UnityEditor.Handles.Label(pos + Vector3.up * 1f, recordingCameras[i].name);
                #endif
            }
        }
    }
} 